# -*- coding: utf-8 -*-
"""Ahmed_Caruso_Obesity

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ePEZYqN9D_OWhFvRvzYo2LbU-3aNVtNW
"""

from google.colab import drive
drive.mount('/content/drive')

"""# load packages"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.stats import norm
import scipy.stats as stats
import seaborn as sns

"""# reading in csv"""

# file path
file_path = "/content/drive/MyDrive/Nutrition,_Physical_Activity,_and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System_20251009.csv"

# read the CSV
df = pd.read_csv(file_path, low_memory=False)

"""# original data"""

# dataset shape and columns
print("\n--- Dataset Shape ---")
print(df.shape)

print("\n--- Columns ---")
for col in df.columns:
    print(col)

# describe numerical columns
print("\n--- Summary Statistics (Numerical Columns) ---")
print(df.describe())

"""# data splitting for early/middle/late period and column selection"""

# separate past and current periods
early_start, early_end = 2011, 2013
middle_start, middle_end = 2016, 2018
late_start, late_end = 2021, 2023

df_early = df[
    ((df['YearStart'] >= early_start) & (df['YearStart'] <= early_end)) |
    ((df['YearEnd'] >= early_start) & (df['YearEnd'] <= early_end))
]

df_middle = df[
    ((df['YearStart'] >= middle_start) & (df['YearStart'] <= middle_end)) |
    ((df['YearEnd'] >= middle_start) & (df['YearEnd'] <= middle_end))
]

df_late = df[
    ((df['YearStart'] >= late_start) & (df['YearStart'] <= late_end)) |
    ((df['YearEnd'] >= late_start) & (df['YearEnd'] <= late_end))
]

# filter needed columns
columns_to_keep = [
    'YearStart', 'YearEnd', 'LocationDesc', 'Question', 'Data_Value',
    'Age(years)', 'Education', 'Sex', 'Income', 'Race/Ethnicity',
    'Low_Confidence_Limit', 'High_Confidence_Limit ', 'Sample_Size'

]

columns_present = [col for col in columns_to_keep if col in df.columns]

# create subsets for early and late dfs
df_early = df_early[columns_present].copy()
df_middle = df_middle[columns_present].copy()
df_late  = df_late[columns_present].copy()

# show final column set
print("\n--- Columns retained for analysis ---")
print(df_early.columns.tolist())

# ensure all states are represented in both periods
early_states = df_early['LocationDesc'].unique()
middle_states = df_middle['LocationDesc'].unique()
late_states = df_late['LocationDesc'].unique()

missing_early = set(middle_states) - set(early_states)
missing_middle = set(early_states) - set(late_states)
missing_late = set(late_states) - set(middle_states)

print(f"\nStates present in late period but missing in early period: {sorted(missing_early)}")
print(f"States present in middle period but missing in early period: {sorted(missing_middle)}")
print(f"States present in early period but missing in late period: {sorted(missing_late)}")

"""# filtering for obesity prevalence rates"""

# filter for obesity question
df_obesity_early = df_early[df_early['Question'].str.contains('Obesity', case=False, na=False)]
df_obesity_middle = df_middle[df_middle['Question'].str.contains('Obesity', case=False, na=False)]
df_obesity_late = df_late[df_late['Question'].str.contains('Obesity', case=False, na=False)]
df_obesity = df[df['Question'].str.contains('Obesity', case=False, na=False)]

print(f"Number of rows for early period ({early_start}-{early_end}): {df_obesity_early.shape[0]}")
print(f"Number of rows for middle period ({middle_start}-{middle_end}): {df_obesity_middle.shape[0]}")
print(f"Number of rows for late period ({late_start}-{late_end}): {df_obesity_late.shape[0]}")

"""# state-specific ECDF"""

state_name = "Connecticut"

# filter data for the selected state
data_early = df_obesity_early[df_obesity_early['LocationDesc'] == state_name]['Data_Value']
data_late = df_obesity_late[df_obesity_late['LocationDesc'] == state_name]['Data_Value']

# convert to numeric (force errors to NaN and drop them)
data_early = pd.to_numeric(data_early, errors='coerce').dropna().values
data_late = pd.to_numeric(data_late, errors='coerce').dropna().values

# compute ECDF for each period
x_early = np.sort(data_early)
y_early = np.arange(1, len(x_early) + 1) / len(x_early)

x_late = np.sort(data_late)
y_late = np.arange(1, len(x_late) + 1) / len(x_late)

# compute medians
median_early = np.median(data_early)
median_late = np.median(data_late)

# plot ECDFs
plt.figure(figsize=(8, 6))
plt.plot(x_early, y_early, linestyle='-', color='blue', label='2011-2013 ECDF', zorder=5)
plt.plot(x_late, y_late, linestyle='--', color='red', label='2019-2021 ECDF', zorder=5)

# median lines
plt.axvline(median_early, color='blue', linestyle='--', linewidth=2, label=f"Median (Early): {median_early:.1f}%", zorder=10)
plt.axvline(median_late, color='red', linestyle='--', linewidth=2, label=f"Median (Late): {median_late:.1f}%", zorder=10)

# normal CDF curves for reference
x_vals = np.linspace(min(x_early.min(), x_late.min()), max(x_early.max(), x_late.max()), 200)
plt.plot(x_vals, norm.cdf(x_vals, loc=mean_early, scale=np.std(data_early)),
         color='blue', linestyle=':', linewidth=2, alpha=0.5, label='Normal CDF (Early)', zorder=1)
plt.plot(x_vals, norm.cdf(x_vals, loc=mean_late, scale=np.std(data_late)),
         color='red', linestyle=':', linewidth=2, alpha=0.5, label='Normal CDF (Late)', zorder=1)

plt.xlabel("Obesity Rate (%)")
plt.ylabel("ECDF")
plt.title(f"ECDF of Obesity Rate for {state_name}: Early vs Late Periods")
plt.grid(True)
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

"""# histogram of mean difference scores (late-early for every state/territory)"""

### plotting histogram of mean differences

early_means = df_obesity_early.groupby('LocationDesc')['Data_Value'].mean().rename('mean_early')
middle_means = df_obesity_middle.groupby('LocationDesc')['Data_Value'].mean().rename('mean_middle')
late_means  = df_obesity_late.groupby('LocationDesc')['Data_Value'].mean().rename('mean_late')

# combine into dataframe
means_df = pd.concat([early_means, middle_means, late_means], axis=1)

# compute difference (late - early)
means_df['mean_diff'] = means_df['mean_late'] - means_df['mean_early']
means_df['upper_mean_dif'] = means_df['mean_late'] - means_df['mean_middle']
means_df['lower_mean_dif'] = means_df['mean_middle'] - means_df['mean_early']

# keep only states that have both early and late values
means_df_common = means_df.dropna(subset=['mean_early', 'mean_late', 'mean_middle']).copy()

# sort by difference
means_df_common = means_df_common.sort_values('mean_diff', ascending=False)

# print basic summary
print("\n--- Mean difference summary (late - early) ---")
print(means_df_common['mean_diff'].describe())

print(f"\nNumber of states with both periods: {means_df_common.shape[0]}")

# plot histogram
plt.figure(figsize=(9,6))
diffs = means_df_common['mean_diff'].values
plt.hist(diffs, bins=15, edgecolor='k', color='lightpink')
plt.axvline(diffs.mean(), color='darkslateblue', linestyle='--', linewidth=4, label=f"Mean diff = {diffs.mean():.2f}")
plt.xlabel('Mean difference (2021-2023 minus 2011-2013) in obesity rate (%)')
plt.ylabel('Number of states')
plt.title('Distribution of Mean Difference in Obesity Rate by State')
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

"""# largest and smallest obesity changes"""

cprint("\n=== Top 5 states with the largest total increase (late - early) ===")
print(means_df_common.sort_values('mean_diff', ascending=False)
      .head(5)[['mean_early','mean_middle','mean_late','mean_diff']])

print("\n=== Bottom 5 states with the smallest increase / largest decrease (late - early) ===")
print(means_df_common.sort_values('mean_diff', ascending=True)
      .head(5)[['mean_early','mean_middle','mean_late','mean_diff']])

# show the interval-specific differences
print("\n=== Top 5 early → middle increases ===")
print(means_df_common.sort_values('lower_mean_dif', ascending=False)
      .head(5)[['mean_early','mean_middle','lower_mean_dif']])

print("\n=== Top 5 middle → late increases ===")
print(means_df_common.sort_values('upper_mean_dif', ascending=False)
      .head(5)[['mean_middle','mean_late','upper_mean_dif']])

# plot overlaid histograms
plt.figure(figsize=(9,6))
# extract data
upper_diffs = means_df_common['upper_mean_dif'].values
lower_diffs = means_df_common['lower_mean_dif'].values
# plot histograms with transparency
plt.hist(lower_diffs, bins=15, alpha=0.6, edgecolor='k', label='2016–2018 minus 2011–2013')
plt.hist(upper_diffs, color='violet', bins=15, alpha=0.6, edgecolor='k', label='2021–2023 minus 2016–2018')

# vertical lines for means
plt.axvline(lower_diffs.mean(), color='blue', linestyle='--', linewidth=2,
            label=f"Mean diff (lower) = {lower_diffs.mean():.2f}")
plt.axvline(upper_diffs.mean(), color='red', linestyle='--', linewidth=2,
            label=f"Mean diff (upper) = {upper_diffs.mean():.2f}")

# labels and formatting
plt.xlabel('Mean difference in obesity rate (%)')
plt.ylabel('Number of states')
plt.title('Change in State-Level Obesity Rates Across Intervals')
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

"""# Demographics"""

for col in df_obesity_early.columns:
    print(col)

# List of demographic columns to check
demographics = ['Age(years)', 'Education', 'Sex', 'Income', 'Race/Ethnicity']

# Function to calculate proportion of non-NA values
def non_na_proportion(df, cols):
    return {col: df[col].notna().mean() for col in cols}

# Proportions for early and late datasets
prop_early = non_na_proportion(df_obesity_early, demographics)
prop_middle = non_na_proportion(df_obesity_middle, demographics)
prop_late = non_na_proportion(df_obesity_late, demographics)
prop_total = non_na_proportion(df_obesity, demographics)

print("Proportion of non-NA rows in df_obesity_early:")
for col, prop in prop_early.items():
    print(f"{col}: {prop:.2%}")

print("\nProportion of non-NA rows in df_obesity_middle:")
for col, prop in prop_middle.items():
    print(f"{col}: {prop:.2%}")

print("\nProportion of non-NA rows in df_obesity_late:")
for col, prop in prop_late.items():
    print(f"{col}: {prop:.2%}")

print("\nProportion of non-NA rows in df_obesity:")
for col, prop in prop_total.items():
    print(f"{col}: {prop:.2%}")

"""# Country wide t-tests"""

# extract the difference arrays
lower = means_df_common['lower_mean_dif'].dropna().values  # pre-COVID difference (2011–2013 to 2016–2018)
upper = means_df_common['upper_mean_dif'].dropna().values  # COVID-era difference (2016–2018 to 2021–2023)

# check that they align (same states)
assert len(lower) == len(upper), "Arrays must be same length (same states)."

# paired t-test
t_stat, p_val = stats.ttest_rel(upper, lower)

# summarize results
mean_lower = np.mean(lower)
mean_upper = np.mean(upper)
diff_means = mean_upper - mean_lower

print(f"Pre-COVID mean difference (2011–2013 → 2016–2018): {mean_lower:.3f}")
print(f"COVID-era mean difference (2016–2018 → 2021–2023): {mean_upper:.3f}")
print(f"Mean difference-in-differences (COVID - pre-COVID): {diff_means:.3f}")
print(f"t-statistic = {t_stat:.3f}, p-value = {p_val:.4f}")

# visualize comparison
plt.figure(figsize=(8,5))
plt.bar(['Pre-COVID', 'COVID-era'], [mean_lower, mean_upper],
        color=['steelblue', 'indianred'], edgecolor='k', alpha=0.8)
plt.ylabel('Mean Change in Obesity Rate (%)')
plt.title('Comparison of Mean Change in Obesity Rate: Pre-COVID vs COVID-Era')
plt.text(0.5, max(mean_lower, mean_upper)*1.02, f"p = {p_val:.4f}", ha='center', fontsize=11)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

"""Paired t-tests compared the rise in obesity over the pre-COVID interval (2011–2013 to 2016–2018) with the rise observed leading into the COVID lockdown period (2016–2018 to 2021–2023). The results show a statistically significant increase in the mean difference, indicating that the rise in obesity was greater during the period including COVID lockdowns than during the preceding standard five-year interval. These findings suggest that COVID-19 may have accelerated the underlying trend in obesity prevalence. However, it is also possible that obesity follows a nonlinear (e.g. exponential) trajectory, in which successive intervals naturally produce larger increases than earlier ones.

# Bootstrap confidence intervals
"""

# extract arrays for the two difference periods
lower_dif = means_df_common['lower_mean_dif'].dropna().values
upper_dif = means_df_common['upper_mean_dif'].dropna().values

# compute observed paired difference
paired_diff = upper_dif - lower_dif
observed_mean_diff = np.mean(paired_diff)

# bootstrap parameters
n_boot = 10000
boot_means = np.empty(n_boot)

np.random.seed(42)

# bootstrap resampling (state-level)
for i in range(n_boot):
    sample_indices = np.random.choice(len(paired_diff), size=len(paired_diff), replace=True)
    boot_sample = paired_diff[sample_indices]
    boot_means[i] = np.mean(boot_sample)

# Compute bootstrap CI (percentile method)
ci_lower = np.percentile(boot_means, 2.5)
ci_upper = np.percentile(boot_means, 97.5)

# Empirical p-value (two-tailed)
p_boot = 2 * min(
    np.mean(boot_means >= 0),
    np.mean(boot_means <= 0)
)

# Print results
print(f"Observed mean difference (COVID - pre-COVID): {observed_mean_diff:.3f}")
print(f"Bootstrap 95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]")
print(f"Empirical p-value: {p_boot:.4f}")

# Plot bootstrap distribution
plt.figure(figsize=(9,6))
plt.hist(boot_means, bins=40, color='skyblue', edgecolor='k', alpha=0.7)
plt.axvline(observed_mean_diff, color='red', linestyle='--', linewidth=2, label=f"Observed mean = {observed_mean_diff:.2f}")
plt.axvline(ci_lower, color='black', linestyle=':', linewidth=1.5, label=f"95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]")
plt.axvline(ci_upper, color='black', linestyle=':', linewidth=1.5)
plt.title("Bootstrap Distribution of Mean Difference in State-Level Obesity Change\n(COVID vs Pre-COVID Intervals)")
plt.xlabel("Mean difference (ΔCOVID − ΔpreCOVID)")
plt.ylabel("Frequency")
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

"""To complement the paired t-test and avoid reliance on distributional assumptions, we conducted a nonparametric bootstrap analysis of the paired state-level differences. We computed the difference between COVID-era change in obesity and its pre-COVID change for each state and generated 10,000 bootstrap resamples of these paired differences by sampling states with replacement. We used these state-level differences to form the empirical sampling distribution from which a 95% confidence interval and two-tailed p-value were derived. This bootstrap approach does not assume normality of state-level differences and provides a robust check on the parametric results. Consistent with the t-test, the bootstrap distribution indicated that the increase in obesity was significantly larger during the interval spanning the COVID period than during the preceding interval.

# Demographic analyses
"""

unique_categories = df_obesity['Race/Ethnicity'].unique()
print(unique_categories)
unique_categories = df_obesity['Age(years)'].unique()
print(unique_categories)
unique_categories = df_obesity['Education'].unique()
print(unique_categories)
unique_categories = df_obesity['Income'].unique()
print(unique_categories)
unique_categories = df_obesity['Sex'].unique()
print(unique_categories)

"""To evaluate demographic differences in obesity trends, we analyzed BRFSS aggregate estimates, each representing a sample-weighted proportion collected for a specific subpopulation (e.g., age group, income category). For each demographic group, we computed weighted mean obesity proportions within three intervals (2011–2013, 2016–2018, and 2021–2023), using the reported sample sizes as weights.
Changes between intervals were estimated by calculating difference scores (early→middle and middle→late). Uncertainty for each difference was quantified using a binomial standard-error approximation, which is appropriate because each aggregate proportion is derived from a finite sample and follows binomial sampling variability. To provide additional robustness, we generated nonparametric bootstrap confidence intervals by resampling aggregates within each interval.
To examine whether shifts in obesity rates accelerated or slowed across time, we conducted Difference-in-Differences (DiD) tests comparing the two interval changes within each subgroup. Due to sparse data in several categories, analyses were limited to demographic groups with adequate coverage across all intervals.

# Income analysis
"""

df_obesity['Data_Value'] = pd.to_numeric(df_obesity['Data_Value'], errors='coerce')
df_obesity['Sample_Size'] = pd.to_numeric(df_obesity['Sample_Size'], errors='coerce')

# Drop rows with missing values in key columns
df_obesity = df_obesity.dropna(subset=['Data_Value', 'Sample_Size'])

# Define time intervals
intervals = {
    'early': (2011, 2013),
    'middle': (2016, 2018),
    'late': (2021, 2023)
}

# Select demographic variable
demographic_col = 'Income'
categories = df_obesity[demographic_col].dropna().unique()

did_results = []
diff_results = []

for cat in categories:
    if pd.isna(cat) or cat == 'Data not reported':
        continue

    df_cat = df_obesity[df_obesity[demographic_col] == cat]

    # Compute weighted means for each interval
    means = {}
    sample_sizes = {}
    for key, (start, end) in intervals.items():
        df_interval = df_cat[(df_cat['YearStart'] >= start) & (df_cat['YearEnd'] <= end)]
        if len(df_interval) == 0:
            continue
        weights = df_interval['Sample_Size']
        proportions = df_interval['Data_Value'] / 100
        means[key] = np.sum(weights * proportions) / np.sum(weights)
        sample_sizes[key] = np.sum(weights)

    # Compute simple differences (early-middle & middle-late)
    if all(k in means for k in ['early', 'middle']):
        diff_results.append({
            'Income': cat,
            'Comparison': 'early-middle',
            'Difference': means['middle'] - means['early']
        })

    if all(k in means for k in ['middle', 'late']):
        diff_results.append({
            'Income': cat,
            'Comparison': 'middle-late',
            'Difference': means['late'] - means['middle']
        })

    # (DiD): slope change
    if all(k in means for k in ['early', 'middle', 'late']):

        D1 = means['middle'] - means['early']
        D2 = means['late'] - means['middle']
        DiD_obs = D1 - D2

        # Data for bootstrapping
        df_early = df_cat[(df_cat['YearStart'] >= 2011) & (df_cat['YearEnd'] <= 2013)]
        df_middle = df_cat[(df_cat['YearStart'] >= 2016) & (df_cat['YearEnd'] <= 2018)]
        df_late = df_cat[(df_cat['YearStart'] >= 2021) & (df_cat['YearEnd'] <= 2023)]

        boot_DiD = []
        n_boot = 5000

        for _ in range(n_boot):
            b_early = df_early.sample(n=len(df_early), replace=True)
            b_middle = df_middle.sample(n=len(df_middle), replace=True)
            b_late = df_late.sample(n=len(df_late), replace=True)

            m_early = np.sum(b_early['Sample_Size'] * b_early['Data_Value']/100) / np.sum(b_early['Sample_Size'])
            m_middle = np.sum(b_middle['Sample_Size'] * b_middle['Data_Value']/100) / np.sum(b_middle['Sample_Size'])
            m_late = np.sum(b_late['Sample_Size'] * b_late['Data_Value']/100) / np.sum(b_late['Sample_Size'])

            D1_b = m_middle - m_early
            D2_b = m_late - m_middle
            boot_DiD.append(D1_b - D2_b)

        ci_lower = np.percentile(boot_DiD, 2.5)
        ci_upper = np.percentile(boot_DiD, 97.5)
        p_boot = np.mean(np.abs(boot_DiD) >= abs(DiD_obs))

        did_results.append({
            'Income': cat,
            'DiD': DiD_obs,
            'CI_lower': ci_lower,
            'CI_upper': ci_upper,
            'p_value': p_boot
        })

# Convert to DataFrames
diff_df = pd.DataFrame(diff_results)
did_df = pd.DataFrame(did_results)

# Prints the DID
print("\n=== Difference-in-Differences (Slope Change) Results by Income Group ===")
print(did_df.sort_values('DiD', ascending=False))


# data prep
plot_df = diff_df.pivot(index='Income', columns='Comparison', values='Difference').reset_index()

# Income group ordering
income_order = [
    "Less than $15,000",
    "$15,000 - $24,999",
    "$25,000 - $34,999",
    "$35,000 - $49,999",
    "$50,000 - $74,999",
    "$75,000 or greater"
]

plot_df['Income'] = (
    plot_df['Income']
    .astype(str)
    .str.strip()
    .replace({
        '75,000 or greater': '$75,000 or greater',
        '$75,000 and greater': '$75,000 or greater',
        '$75,000+': '$75,000 or greater',
        'nan': np.nan
    })
)

plot_df['Income'] = pd.Categorical(plot_df['Income'], categories=income_order, ordered=True)
plot_df = plot_df.sort_values('Income')
plot_df['Income'] = plot_df['Income'].fillna('$75,000 or greater')

# bar plot
plt.figure(figsize=(10,6))
bar_width = 0.35
indices = np.arange(len(plot_df))

plt.bar(indices - bar_width/2, plot_df['early-middle'], width=bar_width,
        label='2011–2013 → 2016–2018 (pre-COVID)', color='skyblue')
plt.bar(indices + bar_width/2, plot_df['middle-late'], width=bar_width,
        label='2016–2018 → 2021–2023 (COVID-era)', color='orchid')

plt.xticks(indices, plot_df['Income'], rotation=45, ha='right')
plt.ylabel('Difference in Mean Obesity Proportion')
plt.title('Obesity Rate Changes by Income Group Across Time Intervals')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.legend()
plt.tight_layout()
plt.show()



"""For the income demographic, we examined how obesity rates changed through our three time intervals: 2011–2013 (early), 2016–2018 (middle), and 2021–2023 (late) using weighted means based the sample size of each data aggregate. For each income group, we first calculated the change in average obesity prevalence between the early–middle and middle–late periods. These raw differences were then visualized in a bar chart, shwoing that the <$15,000 and $25,000–$34,999 groups showed the largest changes in rate over time. To determine whether these visual differences reflected a real change in the underlying trend, we performed a bootstrap Difference-in-Differences (DiD) test for each income category. This test evaluated whether the rate of increase in obesity changed significantly from the pre-COVID period to the COVID-era period. Although some income groups showed large raw differences, the DiD test produced wide confidence intervals and insignificant p-values, indicating that these apparent disparities were not statistically significant. This is likely due to limited sample sizes and substantial variability within each interval.

# Race/Ethnicity analysis
"""

df_obesity['Data_Value'] = pd.to_numeric(df_obesity['Data_Value'], errors='coerce')
df_obesity['Sample_Size'] = pd.to_numeric(df_obesity['Sample_Size'], errors='coerce')

df_obesity = df_obesity.dropna(subset=['Data_Value', 'Sample_Size'])

intervals = {
    'early': (2011, 2013),
    'middle': (2016, 2018),
    'late': (2021, 2023)
}

demographic_col = 'Race/Ethnicity'
categories = df_obesity[demographic_col].dropna().unique()

results = []


for cat in categories:
    if pd.isna(cat):
        continue

    df_cat = df_obesity[df_obesity[demographic_col] == cat]

    # weighted mean
    means = {}
    n_sizes = {}

    for key, (start, end) in intervals.items():
        df_int = df_cat[(df_cat['YearStart'] >= start) & (df_cat['YearEnd'] <= end)]
        if len(df_int) == 0:
            continue
        proportions = df_int['Data_Value'] / 100
        weights = df_int['Sample_Size']

        means[key] = np.sum(weights * proportions) / np.sum(weights)
        n_sizes[key] = np.sum(weights)

    # Skip groups missing any interval
    if not all(k in means for k in ['early', 'middle', 'late']):
        continue

    # Raw differences (early to middle, middle to late)
    diff_early_middle = means['middle'] - means['early']
    diff_middle_late = means['late'] - means['middle']

    results.append({
        'Race/Ethnicity': cat,
        'Comparison': 'early-middle',
        'Difference': diff_early_middle
    })

    results.append({
        'Race/Ethnicity': cat,
        'Comparison': 'middle-late',
        'Difference': diff_middle_late
    })

    # DID
    D1 = diff_early_middle
    D2 = diff_middle_late
    DiD_obs = D1 - D2

    # Bootstrap each interval independently
    df_early = df_cat[(df_cat['YearStart'] >= 2011) & (df_cat['YearEnd'] <= 2013)]
    df_middle = df_cat[(df_cat['YearStart'] >= 2016) & (df_cat['YearEnd'] <= 2018)]
    df_late = df_cat[(df_cat['YearStart'] >= 2021) & (df_cat['YearEnd'] <= 2023)]

    boot_DiD = []
    n_boot = 5000

    for _ in range(n_boot):
        b_early = df_early.sample(n=len(df_early), replace=True)
        b_middle = df_middle.sample(n=len(df_middle), replace=True)
        b_late = df_late.sample(n=len(df_late), replace=True)

        m_early = np.sum(b_early['Sample_Size'] * b_early['Data_Value']/100) / np.sum(b_early['Sample_Size'])
        m_middle = np.sum(b_middle['Sample_Size'] * b_middle['Data_Value']/100) / np.sum(b_middle['Sample_Size'])
        m_late = np.sum(b_late['Sample_Size'] * b_late['Data_Value']/100) / np.sum(b_late['Sample_Size'])

        D1_b = m_middle - m_early
        D2_b = m_late - m_middle
        boot_DiD.append(D1_b - D2_b)

    # CI and bootstrap p
    ci_lower = np.percentile(boot_DiD, 2.5)
    ci_upper = np.percentile(boot_DiD, 97.5)
    p_boot = np.mean(np.abs(boot_DiD) >= abs(DiD_obs))

    results.append({
        'Race/Ethnicity': cat,
        'Comparison': 'slope-change (DiD)',
        'Difference': DiD_obs,
        'CI_lower': ci_lower,
        'CI_upper': ci_upper,
        'p_value': p_boot
    })



results_df = pd.DataFrame(results)

# Print only the Difference-in-Differences rows
print("\n=== Difference-in-Differences (DiD) Results ===")
print(results_df[results_df['Comparison'] == 'slope-change (DiD)'])


plot_df = results_df.pivot(index='Race/Ethnicity', columns='Comparison', values='Difference').reset_index()

# Keep only groups with early-middle data
plot_df = plot_df.dropna(subset=['early-middle'])

# enforce consistent order
race_order = [
    'Asian',
    'Hispanic',
    'Non-Hispanic Black',
    'American Indian/Alaska Native',
    'Hawaiian/Pacific Islander',
    '2 or more races',
    'Other'
]

plot_df['Race/Ethnicity'] = pd.Categorical(plot_df['Race/Ethnicity'], categories=race_order, ordered=True)
plot_df = plot_df.sort_values('Race/Ethnicity')

# Plot
plt.figure(figsize=(10,6))
bar_width = 0.35
indices = np.arange(len(plot_df))

plt.bar(indices - bar_width/2, plot_df['early-middle'], width=bar_width,
        label='2011–2013 → 2016–2018 (pre-COVID)')
plt.bar(indices + bar_width/2, plot_df['middle-late'], width=bar_width,
        label='2016–2018 → 2021–2023 (COVID-era)')

plt.xticks(indices, plot_df['Race/Ethnicity'], rotation=45, ha='right')
plt.ylabel('Difference in Mean Obesity Proportion')
plt.title('Obesity Change Across Time by Race/Ethnicity')
plt.axhline(0, color='black', linestyle='--')
plt.tight_layout()
plt.legend()
plt.show()

"""For the race/ethnicity analyses, we applied the same difference-in-differences (DiD) structure used in the income section. We divided the data into three intervals (2011–2013, 2016–2018, and 2021–2023), calculated weighted mean obesity prevalence for each racial/ethnic group within each interval, and then computed two change scores: the pre-COVID change (early → middle) and the COVID-era change (middle → late). For each comparison, we estimated standard errors, z-tests, and bootstrap confidence intervals to assess whether the observed changes were statistically meaningful.

Overall, the results show that most racial and ethnic groups experienced very similar increases across both intervals, indicating relatively stable growth over time. However, two groups stood out. Hispanic individuals showed a modestly larger increase in obesity during both periods compared to other groups. More prominently, the Hawaiian/Pacific Islander group exhibited much larger absolute obesity levels and noticeably higher increases across intervals—both of their bars were substantially taller than those of the other groups, reflecting both higher baseline prevalence and steeper growth. Despite these visual differences, all comparisons were not statistically significant.

# Sex analysis
"""

# Ensure numeric columns
df_obesity['Data_Value'] = pd.to_numeric(df_obesity['Data_Value'], errors='coerce')
df_obesity['Sample_Size'] = pd.to_numeric(df_obesity['Sample_Size'], errors='coerce')

# Drop rows with missing values
df_obesity = df_obesity.dropna(subset=['Data_Value', 'Sample_Size'])

# Define intervals
intervals = {
    'early': (2011, 2013),
    'middle': (2016, 2018),
    'late': (2021, 2023)
}

# Select demographic variable
demographic_col = 'Sex'
categories = df_obesity[demographic_col].dropna().unique()

results = []

for cat in categories:
    if pd.isna(cat):
        continue

    df_cat = df_obesity[df_obesity[demographic_col] == cat]

    # Compute weighted means for each interval
    means = {}
    sample_sizes = {}
    for key, (start, end) in intervals.items():
        df_interval = df_cat[(df_cat['YearStart'] >= start) & (df_cat['YearEnd'] <= end)]
        if len(df_interval) == 0:
            print(f" Warning: '{cat}' has NO records in {key} interval ({start}-{end})")
            continue
        weights = df_interval['Sample_Size']
        proportions = df_interval['Data_Value'] / 100
        means[key] = np.sum(weights * proportions) / np.sum(weights)
        sample_sizes[key] = np.sum(weights)
        print(f" {cat} | {key}: mean={means[key]:.3f}, n={sample_sizes[key]}")

    # Compare early-middle and middle-late
    comparisons = {
        'early-middle': ('early', 'middle'),
        'middle-late': ('middle', 'late')
    }

    for label, (start_key, end_key) in comparisons.items():
        if start_key not in means or end_key not in means:
            print(f" Skipping '{cat}' for {label} — missing {start_key} or {end_key} mean.")
            continue

        p1, p2 = means[start_key], means[end_key]
        n1, n2 = sample_sizes[start_key], sample_sizes[end_key]
        se_diff = np.sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)
        z = (p2 - p1) / se_diff
        p_value = 2 * (1 - norm.cdf(abs(z)))

        # Bootstrap confidence intervals
        n_boot = 5000
        df_start = df_cat[(df_cat['YearStart'] >= intervals[start_key][0]) & (df_cat['YearEnd'] <= intervals[start_key][1])]
        df_end = df_cat[(df_cat['YearStart'] >= intervals[end_key][0]) & (df_cat['YearEnd'] <= intervals[end_key][1])]
        boot_diffs = []
        for _ in range(n_boot):
            start_sample = df_start.sample(n=len(df_start), replace=True)
            end_sample = df_end.sample(n=len(df_end), replace=True)
            start_mean = np.sum(start_sample['Sample_Size'] * start_sample['Data_Value']/100) / np.sum(start_sample['Sample_Size'])
            end_mean = np.sum(end_sample['Sample_Size'] * end_sample['Data_Value']/100) / np.sum(end_sample['Sample_Size'])
            boot_diffs.append(end_mean - start_mean)

        ci_lower = np.percentile(boot_diffs, 2.5)
        ci_upper = np.percentile(boot_diffs, 97.5)

        results.append({
            'Sex': cat,
            'Comparison': label,
            'Start Mean': p1,
            'End Mean': p2,
            'Difference': p2 - p1,
            'SE_diff': se_diff,
            'z': z,
            'p_value': p_value,
            'CI_lower': ci_lower,
            'CI_upper': ci_upper
        })

# Convert to DataFrame and sort
results_df = pd.DataFrame(results)
results_df.sort_values(['Comparison', 'Difference'], ascending=[True, False], inplace=True)
print(results_df)

# Pivot for plotting
plot_df = results_df.pivot(index='Sex', columns='Comparison', values='Difference').reset_index()

# Plot
plt.figure(figsize=(8,5))
bar_width = 0.35
indices = np.arange(len(plot_df))

plt.bar(indices - bar_width/2, plot_df['early-middle'], width=bar_width,
        label='2011-2013 → 2016-2018 (pre-COVID)', color='skyblue')
plt.bar(indices + bar_width/2, plot_df['middle-late'], width=bar_width,
        label='2016-2018 → 2021-2023 (COVID-era)', color='orchid')

plt.xticks(indices, plot_df['Sex'], rotation=0)
plt.ylabel('Difference in Mean Obesity Proportion')
plt.title('Comparison of Obesity Changes by Sex Across Intervals')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.legend()
plt.tight_layout()
plt.show()

"""# Age analysis"""

# Ensure numeric columns
df_obesity['Data_Value'] = pd.to_numeric(df_obesity['Data_Value'], errors='coerce')
df_obesity['Sample_Size'] = pd.to_numeric(df_obesity['Sample_Size'], errors='coerce')

# Drop rows with missing values
df_obesity = df_obesity.dropna(subset=['Data_Value', 'Sample_Size'])

# Define intervals
intervals = {
    'early': (2011, 2013),
    'middle': (2016, 2018),
    'late': (2021, 2023)
}

# Select demographic variable
demographic_col = 'Age(years)'
categories = df_obesity[demographic_col].dropna().unique()

results = []

for cat in categories:
    if pd.isna(cat):
        continue

    df_cat = df_obesity[df_obesity[demographic_col] == cat]

    # Compute weighted means for each interval
    means = {}
    sample_sizes = {}
    for key, (start, end) in intervals.items():
        df_interval = df_cat[(df_cat['YearStart'] >= start) & (df_cat['YearEnd'] <= end)]
        if len(df_interval) == 0:
            continue
        weights = df_interval['Sample_Size']
        proportions = df_interval['Data_Value'] / 100
        means[key] = np.sum(weights * proportions) / np.sum(weights)
        sample_sizes[key] = np.sum(weights)

    # --- Difference-in-Differences (DiD) ---
    if all(k in means for k in ['early', 'middle', 'late']):
        D1 = means['middle'] - means['early']
        D2 = means['late'] - means['middle']
        DiD_obs = D1 - D2

        # Bootstrap DiD
        df_early = df_cat[(df_cat['YearStart'] >= 2011) & (df_cat['YearEnd'] <= 2013)]
        df_middle = df_cat[(df_cat['YearStart'] >= 2016) & (df_cat['YearEnd'] <= 2018)]
        df_late = df_cat[(df_cat['YearStart'] >= 2021) & (df_cat['YearEnd'] <= 2023)]

        boot_DiD = []
        n_boot = 5000
        for _ in range(n_boot):
            b_early = df_early.sample(n=len(df_early), replace=True)
            b_middle = df_middle.sample(n=len(df_middle), replace=True)
            b_late = df_late.sample(n=len(df_late), replace=True)

            m_early = np.sum(b_early['Sample_Size'] * b_early['Data_Value']/100) / np.sum(b_early['Sample_Size'])
            m_middle = np.sum(b_middle['Sample_Size'] * b_middle['Data_Value']/100) / np.sum(b_middle['Sample_Size'])
            m_late = np.sum(b_late['Sample_Size'] * b_late['Data_Value']/100) / np.sum(b_late['Sample_Size'])

            D1_b = m_middle - m_early
            D2_b = m_late - m_middle
            boot_DiD.append(D1_b - D2_b)

        ci_lower = np.percentile(boot_DiD, 2.5)
        ci_upper = np.percentile(boot_DiD, 97.5)
        p_boot = np.mean(np.abs(boot_DiD) >= abs(DiD_obs))

        results.append({
            'Age': cat,
            'Comparison': 'slope-change (DiD)',
            'Start Mean': means['early'],
            'End Mean': means['late'],
            'Difference': DiD_obs,
            'SE_diff': np.nan,
            'z': np.nan,
            'p_value': p_boot,
            'CI_lower': ci_lower,
            'CI_upper': ci_upper
        })

# Convert to DataFrame and print only DiD rows
results_df = pd.DataFrame(results)
did_df = results_df[results_df['Comparison'] == 'slope-change (DiD)']
print(did_df)

#
plot_df = pd.DataFrame()
for label, (start_key, end_key) in {'early-middle': ('early','middle'), 'middle-late': ('middle','late')}.items():
    diffs = []
    for cat in categories:
        df_cat = df_obesity[df_obesity[demographic_col] == cat]
        if start_key not in means or end_key not in means:
            diffs.append(np.nan)
            continue
        weights_start = df_cat[(df_cat['YearStart'] >= intervals[start_key][0]) & (df_cat['YearEnd'] <= intervals[start_key][1])]['Sample_Size']
        values_start = df_cat[(df_cat['YearStart'] >= intervals[start_key][0]) & (df_cat['YearEnd'] <= intervals[start_key][1])]['Data_Value']/100
        weights_end = df_cat[(df_cat['YearStart'] >= intervals[end_key][0]) & (df_cat['YearEnd'] <= intervals[end_key][1])]['Sample_Size']
        values_end = df_cat[(df_cat['YearStart'] >= intervals[end_key][0]) & (df_cat['YearEnd'] <= intervals[end_key][1])]['Data_Value']/100
        mean_start = np.sum(weights_start*values_start)/np.sum(weights_start)
        mean_end = np.sum(weights_end*values_end)/np.sum(weights_end)
        diffs.append(mean_end - mean_start)
    plot_df[label] = diffs
plot_df['Age'] = categories

# Order ages
age_order = ['18 - 24', '25 - 34', '35 - 44', '45 - 54', '55 - 64', '65 or older']
plot_df['Age'] = pd.Categorical(plot_df['Age'], categories=age_order, ordered=True)
plot_df = plot_df.sort_values('Age')

plt.figure(figsize=(10,6))
bar_width = 0.35
indices = np.arange(len(plot_df))

plt.bar(indices - bar_width/2, plot_df['early-middle'], width=bar_width,
        label='2011-2013 → 2016-2018 (pre-COVID)', color='skyblue')
plt.bar(indices + bar_width/2, plot_df['middle-late'], width=bar_width,
        label='2016-2018 → 2021-2023 (COVID-era)', color='orchid')

plt.xticks(indices, plot_df['Age'], rotation=45, ha='right')
plt.ylabel('Difference in Mean Obesity Proportion')
plt.title('Comparison of Obesity Changes by Age Group Across Intervals')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.legend()
plt.tight_layout()
plt.show()

"""For the Age analysis, we computed weighted mean obesity proportions for three intervals (2011–2013, 2016–2018, 2021–2023) and calculated the differences for pre-COVID (early→middle) and COVID-era (middle→late) periods for each age group. The bar plot shows that younger adults (18–24, 25–34, 35–44) experienced relatively larger increases during the COVID-era compared to the pre-COVID period, with the COVID-era bars roughly 1.5 times taller than the pre-COVID bars. Middle-aged adults (45–54) also saw increases in both periods, though the difference between the periods was smaller. For older adults (55–64), the COVID-era increase was the largest among all groups, while the pre-COVID increase was the smallest positive change. Adults aged 65 and older exhibited decreases in both periods, with a larger decline during the COVID-era interval. Overall, these results highlight that mid-to-younger adults experienced the most pronounced increases in obesity rates during the COVID-era, whereas older adults continued to show decreasing trends.

The two results that stand out are 55-64 and 65+. We believe the 55-64 result comes from COVID-era behavioral changes having the greatest effect on 55-64 year olds. Considering the higher risks associated with COVID for this group, these individuals may have undergone the greatest behavioral changes resulting from the pandemic, leading to more sedentary lifestyles causing higher obesity rates. For 65+ individuals both bars are negative, showing that obesity decreased from 2011/13 to 2016/18 and a greater decrease between 2016/18 to 2021/23. We believe the negative rates here are caused by a larger portion of the population (Baby Boomers) increasing in age from 2011-2023. Considering people naturally begin to lose weight after age 65, these negative rates could result from the averga eage within the 65+ group increasing throughout the collection of our data. Furthermore, COVID lockdowns likely exacerbated this pattern, resulting in the greater decrease for the COVID-era period.

# Education analysis
"""

# Ensure numeric columns
df_obesity['Data_Value'] = pd.to_numeric(df_obesity['Data_Value'], errors='coerce')
df_obesity['Sample_Size'] = pd.to_numeric(df_obesity['Sample_Size'], errors='coerce')

# Drop rows with missing values
df_obesity = df_obesity.dropna(subset=['Data_Value', 'Sample_Size'])

# Define intervals
intervals = {
    'early': (2011, 2013),
    'middle': (2016, 2018),
    'late': (2021, 2023)
}

# Select demographic variable
demographic_col = 'Education'
categories = df_obesity[demographic_col].dropna().unique()

results = []

for cat in categories:
    if pd.isna(cat):
        continue

    df_cat = df_obesity[df_obesity[demographic_col] == cat]

    # Compute weighted means for each interval
    means = {}
    sample_sizes = {}
    for key, (start, end) in intervals.items():
        df_interval = df_cat[(df_cat['YearStart'] >= start) & (df_cat['YearEnd'] <= end)]
        if len(df_interval) == 0:
            print(f" Warning: '{cat}' has NO records in {key} interval ({start}-{end})")
            continue
        weights = df_interval['Sample_Size']
        proportions = df_interval['Data_Value'] / 100
        means[key] = np.sum(weights * proportions) / np.sum(weights)
        sample_sizes[key] = np.sum(weights)
        print(f" {cat} | {key}: mean={means[key]:.3f}, n={sample_sizes[key]}")

    # Compare early-middle and middle-late
    comparisons = {
        'early-middle': ('early', 'middle'),
        'middle-late': ('middle', 'late')
    }

    for label, (start_key, end_key) in comparisons.items():
        if start_key not in means or end_key not in means:
            print(f" Skipping '{cat}' for {label} — missing {start_key} or {end_key} mean.")
            continue

        p1, p2 = means[start_key], means[end_key]
        n1, n2 = sample_sizes[start_key], sample_sizes[end_key]
        se_diff = np.sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)
        z = (p2 - p1) / se_diff
        p_value = 2 * (1 - norm.cdf(abs(z)))

        # Bootstrap confidence intervals
        n_boot = 5000
        df_start = df_cat[(df_cat['YearStart'] >= intervals[start_key][0]) & (df_cat['YearEnd'] <= intervals[start_key][1])]
        df_end = df_cat[(df_cat['YearStart'] >= intervals[end_key][0]) & (df_cat['YearEnd'] <= intervals[end_key][1])]
        boot_diffs = []
        for _ in range(n_boot):
            start_sample = df_start.sample(n=len(df_start), replace=True)
            end_sample = df_end.sample(n=len(df_end), replace=True)
            start_mean = np.sum(start_sample['Sample_Size'] * start_sample['Data_Value']/100) / np.sum(start_sample['Sample_Size'])
            end_mean = np.sum(end_sample['Sample_Size'] * end_sample['Data_Value']/100) / np.sum(end_sample['Sample_Size'])
            boot_diffs.append(end_mean - start_mean)

        ci_lower = np.percentile(boot_diffs, 2.5)
        ci_upper = np.percentile(boot_diffs, 97.5)

        results.append({
            'Education': cat,
            'Comparison': label,
            'Start Mean': p1,
            'End Mean': p2,
            'Difference': p2 - p1,
            'SE_diff': se_diff,
            'z': z,
            'p_value': p_value,
            'CI_lower': ci_lower,
            'CI_upper': ci_upper
        })

# Convert to DataFrame and sort
results_df = pd.DataFrame(results)
results_df.sort_values(['Comparison', 'Difference'], ascending=[True, False], inplace=True)
print(results_df)

# Pivot for plotting
plot_df = results_df.pivot(index='Education', columns='Comparison', values='Difference').reset_index()

# Optional: set education order for clarity
education_order = ['Less than high school', 'High school graduate', 'Some college or technical sch', 'College graduate']
plot_df['Education'] = pd.Categorical(plot_df['Education'], categories=education_order, ordered=True)
plot_df = plot_df.sort_values('Education')

# Plot
plt.figure(figsize=(10,6))
bar_width = 0.35
indices = np.arange(len(plot_df))

plt.bar(indices - bar_width/2, plot_df['early-middle'], width=bar_width,
        label='2011-2013 → 2016-2018 (pre-COVID)', color='skyblue')
plt.bar(indices + bar_width/2, plot_df['middle-late'], width=bar_width,
        label='2016-2018 → 2021-2023 (COVID-era)', color='orchid')

plt.xticks(indices, plot_df['Education'], rotation=45, ha='right')
plt.ylabel('Difference in Mean Obesity Proportion')
plt.title('Comparison of Obesity Changes by Education Level Across Intervals')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.legend()
plt.tight_layout()
plt.show()